{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results = pd.DataFrame(columns=['meta', 'hid_num', 'epochs', 'worker', 'time_started', 'time_completed', 'duration_seconds', 'path'])\n",
    "params = {'meta': 'meta', 'epochs per task': 'epochs', 'hidden layers': 'hid_num'}\n",
    "ix = 0\n",
    "traverse = os.walk('.', topdown=False)\n",
    "while True:\n",
    "    try:\n",
    "        dir = traverse.__next__()\n",
    "        # find last-child dir\n",
    "        if not dir[1] and dir[0] != \"./.ipynb_checkpoints\":\n",
    "            # open hyperparams file and get meta, hid_num, epochs\n",
    "            with open(dir[0] + '/hyperparameters.txt', 'r') as f:\n",
    "                file = yaml.load(f, Loader=yaml.Loader)\n",
    "                for param, df_param in params.items():\n",
    "                    for item in file:\n",
    "                        if param in item.keys():\n",
    "                            if type(item[param]) == list:\n",
    "                                df_results.loc[ix, df_param] = item[param][0]\n",
    "                            else:\n",
    "                                df_results.loc[ix, df_param] = item[param]\n",
    "            \n",
    "            # get worker number\n",
    "            worker_num = re.findall(r\"^./results (\\d)\", dir[0])[0]\n",
    "            df_results.loc[ix, 'worker'] = worker_num\n",
    "            \n",
    "            time = dir[0].split('/')[-1].split('_')[0]\n",
    "            date = dir[0].split('/')[-2]\n",
    "\n",
    "            dt = (date + '-' + time)\n",
    "            df_results.loc[ix, 'time_started'] = pd.to_datetime(dt, format='%Y-%m-%d-%H-%M-%S')\n",
    "            \n",
    "            df_results.loc[ix, 'old_path'] = dir[0]\n",
    "            \n",
    "            ix += 1\n",
    "    except StopIteration:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seba/miniforge3/envs/ml-base/lib/python3.9/site-packages/pandas/core/arrays/datetimelike.py:1187: PerformanceWarning: Adding/subtracting object-dtype array to DatetimeArray not vectorized\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df_results['time_completed'] = df_results.groupby('worker').time_started.shift(-1)\n",
    "\n",
    "df_results.dropna(inplace=True, subset=['time_completed'])\n",
    "df_results.duration_seconds = pd.to_timedelta(df_results.time_completed - df_results.time_started).dt.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results['path'] = df_results.apply(lambda x: os.path.join('./results', str(x.meta)+\"_\"+str(x.hid_num)+\"_\"+str(x.epochs)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.to_csv('results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1983208fc3b676051846d4560864203f9ebdf64099edd8febcc8dd3d7f3fa9dd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('ml-base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
