{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPxfLPWD8yCWFw9MOrh+nR5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"01ea6cc3931c4c1c92053bf99df7d0ee":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_51cde6730e2f432c9b242c9230e7b524","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_fb750223edcc428d9d05f5eb59436e2e","IPY_MODEL_526fcf9bdd044c87a2ac734a157f066d","IPY_MODEL_5b0ac9a5304c4e41b5506510a726b402"]}},"51cde6730e2f432c9b242c9230e7b524":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"fb750223edcc428d9d05f5eb59436e2e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ebaa479201214aea9bcab4737f23b29c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"  0%","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8ba6f263854d49d481f9271d1020d1df"}},"526fcf9bdd044c87a2ac734a157f066d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c515bcded77347b995aa4b1cc35e0035","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"danger","max":100,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":0,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0a73ca26e2374ac6bfc3589eb83070ce"}},"5b0ac9a5304c4e41b5506510a726b402":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_view_name":"HTMLView","style":"IPY_MODEL_0379162367464b6b8605e6ed19264eeb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 0/100 [00:01&lt;?, ?it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_10dac26877d14bc1958bf28e85113a66"}},"ebaa479201214aea9bcab4737f23b29c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8ba6f263854d49d481f9271d1020d1df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c515bcded77347b995aa4b1cc35e0035":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0a73ca26e2374ac6bfc3589eb83070ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"0379162367464b6b8605e6ed19264eeb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"10dac26877d14bc1958bf28e85113a66":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"A9I3kFqw2PMb","executionInfo":{"status":"ok","timestamp":1635729887848,"user_tz":300,"elapsed":3630,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["%%capture\n","!pip install tensorflow-addons[tensorflow]"],"execution_count":140,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlVP6GN65QNc","executionInfo":{"status":"ok","timestamp":1635624020234,"user_tz":300,"elapsed":19999,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"4314350f-6c29-49af-f673-773d0eb7dd4b"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd \"/content/drive/MyDrive/Courses/Fall 2021/dlsys/bnn-cf-vs-robust\""],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/MyDrive/Courses/Fall 2021/dlsys/bnn-cf-vs-robust\n"]}]},{"cell_type":"code","metadata":{"id":"82nt9XA_G19_","executionInfo":{"status":"ok","timestamp":1635729890865,"user_tz":300,"elapsed":104,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["import os, glob \n","import numpy as np\n","import pandas as pd"],"execution_count":142,"outputs":[]},{"cell_type":"code","metadata":{"id":"Form4NmqELj3","executionInfo":{"status":"ok","timestamp":1635729891924,"user_tz":300,"elapsed":184,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import Model\n","\n","import tensorflow.image as transforms"],"execution_count":143,"outputs":[]},{"cell_type":"code","metadata":{"id":"ORseizqXTubf","executionInfo":{"status":"ok","timestamp":1635729894948,"user_tz":300,"elapsed":161,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["def standardize_gray_image(image, label):\n","    # see https://www.tensorflow.org/api_docs/python/tf/image/per_image_standardization\n","    mean_img, std_img = tf.math.reduce_mean(image), tf.math.reduce_std(image)\n","    num_els = 1.0 * image.shape[0] * image.shape[1]\n","    adjusted_stddev = tf.maximum(std_img, 1.0/tf.math.sqrt(num_els))\n","    image = (image - mean_img)/adjusted_stddev\n","    return image, label\n","\n","def permute_gray_image(image, label): \n","    rimg = tf.reshape(image, [image.shape[0] * image.shape[1]])\n","    permut = list(np.random.permutation(len(rimg)))\n","    rimg = tf.gather(rimg, indices=permut)\n","    image = tf.reshape(rimg, image.shape)\n","    return image, label\n","\n","def test_permute(image):\n","    import matplotlib.pyplot as plt\n","    # original \n","    plt.subplot(131)\n","    plt.imshow(image)\n","    plt.title('original')\n","    # permute pixels\n","    rimg = tf.reshape(image, -1)\n","    permut = list(np.random.permutation(len(rimg)))\n","    rimg = tf.gather(rimg, indices=permut)\n","    plt.subplot(132)\n","    plt.imshow(tf.reshape(rimg, (28, 28)))\n","    plt.title('permuted')\n","    # recover for checking  \n","    rimg = tf.gather(rimg, indices=tf.math.invert_permutation(permut))\n","    plt.subplot(133)\n","    plt.imshow(tf.reshape(rimg, (28, 28)))\n","    plt.title('recovered')\n"],"execution_count":144,"outputs":[]},{"cell_type":"code","metadata":{"id":"r1uwTTwiKq7Z","executionInfo":{"status":"ok","timestamp":1635729897365,"user_tz":300,"elapsed":184,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["def parse_task(full_task, sep='-'):\n","    # e.g 'MNIST'   -> {'action': 'none', 'task':'MNIST'}\n","    # e.g 'p-MNIST' -> {'action': 'p', 'task':'MNIST'}\n","    if sep not in full_task: \n","        action, task = 'none', full_task\n","    else: \n","        action, task = full_task.split(sep)\n","    return task, action\n","    \n","\n","def create_data_iter(task, action='none', batch_size=100, return_dict=False, \n","                     shuff_buffsz=2000, map_npar=tf.data.AUTOTUNE,\n","                     ds_prefetch=True, ds_cache=True, return_iters=True):\n","    task = task.upper() \n","\n","    if task in ['MNIST', 'FMNIST']:\n","        # Load data \n","        tf_ds = tf.keras.datasets.mnist if task == 'MNIST' else tf.keras.datasets.fashion_mnist\n","        x, y, ds = dict(), dict(), dict()\n","        (x['train'], y['train']), (x['test'], y['test']) = tf_ds.load_data()\n","        for k in ['train', 'test']:\n","            x[k] = (x[k]/255.0).astype('float32')\n","        \n","        # Create tensor dataset \n","        ds = {k: tf.data.Dataset.from_tensor_slices((x[k],y[k])) for k in ['train', 'test']}\n","\n","        # Perform permutation \n","        if action.lower() in ['p', 'perm', 'permuted']: \n","            ds = {k: v.map(permute_gray_image, num_parallel_calls=map_npar) for k,v in ds.items()}\n","\n","        # Perform image standardization \n","        ds = {k: v.map(standardize_gray_image, num_parallel_calls=map_npar) for k,v in ds.items()}\n","\n","        # Prepare for training + batching \n","        ds['train'] = ds['train'].shuffle(buffer_size=shuff_buffsz)\n","        ds = {k: v.batch(batch_size) for k,v in ds.items()}\n","\n","        # Optional to speedup\n","        if ds_prefetch: ds = {k: v.prefetch(tf.data.AUTOTUNE) for k,v in ds.items()}\n","        if ds_cache: ds = {k: v.cache() for k,v in ds.items()}\n","\n","        # # Create iterators\n","        if return_iters: ds = {k: iter(v) for k,v in ds.items()}\n","\n","        if return_dict: return ds\n","        return ds['train'], ds['test']       \n","         \n","    else:\n","        raise('\"%s\" task not implemented' %(task))\n","    "],"execution_count":145,"outputs":[]},{"cell_type":"code","metadata":{"id":"PZfPFghtnUxw","executionInfo":{"status":"ok","timestamp":1635729901654,"user_tz":300,"elapsed":121,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["batch_size = 100\n","task_sequences = ['MNIST', 'p-MNIST', 'p-MNIST', 'p-MNIST']"],"execution_count":146,"outputs":[]},{"cell_type":"code","metadata":{"id":"I8hDlOGK0BBe","executionInfo":{"status":"ok","timestamp":1635728706989,"user_tz":300,"elapsed":780,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["ds = create_data_iter('MNIST', batch_size=batch_size, return_dict=True, return_iters=False)"],"execution_count":79,"outputs":[]},{"cell_type":"code","metadata":{"id":"xR69Ux-CtXqy"},"source":["ds = []\n","for full_task in task_sequences:\n","    task, action = parse_task(full_task)\n","    ds.append(create_data_iter(task, action, batch_size=batch_size, return_dict=True))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttDAJqKkOtQN","executionInfo":{"status":"ok","timestamp":1635734865519,"user_tz":300,"elapsed":615,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import layers, initializers\n","from tensorflow.keras import Model, Sequential\n","\n","@tf.custom_gradient\n","def SignActivation(x):\n","    y = tf.sign(x)\n","    def grad(grad_output):\n","        # use hardtanh gradient (see paper): anything with abs() > 1 -> 0\n","        return tf.where(tf.abs(x) > 1.0, 0.0, grad_output)\n","    return y, grad\n","\n","def Binarize(tensor):\n","    return tf.sign(tensor)\n","\n","class BinarizeLinear(layers.Layer):\n","    '''\n","    units:          number of units for layer \n","    init_type:      'gauss' or 'uniform' for weight initialization in Dense layer\n","    init_width:     used for initialization widths or stddev for weight initialization\n","    dropout_rate:   if not None, will use to construct Dropout layer\n","    act_fun:        if not None, activation function; currently only 'sign' (SignActivation)\n","    norm_type:      if not None, will use for normalization layer; currently only 'bn' (batchnorm)\n","    bin_inp:        (TODO) whether to normalize input; in paper says NO but unclear in code does   \n","    '''\n","    def __init__(self, units, init_type = 'gauss', init_width = 0.01, \n","                 dropout_rate = None, norm_type = 'bn', act_fun = 'sign',\n","                 bin_inp = False, name = 'bfc'):\n","        \n","        super(BinarizeLinear, self).__init__()\n","        self.units = units\n","        self.init_type = init_type\n","        self.init_width = init_width\n","        self.dropout_rate = dropout_rate\n","        self.act_fun = act_fun\n","        self.norm_type = norm_type\n","        self.bin_inp = bin_inp\n","        \n","    def get_dense_initializer(self): \n","        kernel_init = 'glorot_uniform'\n","        init_width = self.init_width\n","        if self.init_type == 'gauss': \n","            kernel_init = initializers.RandomNormal(mean=0.0, stddev=init_width)\n","        if self.init_type == 'uniform': \n","            kernel_init = initializers.RandomUniform(minval=-init_width/2, maxval=init_width/2)\n","        return kernel_init\n","    \n","    def build(self, input_shape): \n","        self.inp_dim = input_shape \n","        \n","        # Dense linear layer \n","        self.fc = layers.Dense(self.units, use_bias=False, activation=None, \n","                                kernel_initializer=self.get_dense_initializer())\n","        self.fc.build(input_shape)\n","        \n","        # Create 'org' (i.e. hidden weight) in weight and binarize        \n","        if not hasattr(self.fc.kernel,'org'):\n","            self.fc.kernel.org = tf.identity(self.fc.kernel)\n","        self.fc.kernel.assign(Binarize(self.fc.kernel.org))\n","        \n","        # Create dropout layer\n","        if self.dropout_rate:\n","            self.dropout = layers.Dropout(rate=self.dropout_rate)\n","        \n","        # Create normalization layer \n","        if self.norm_type:\n","            if self.norm_type == 'bn': \n","                self.norm = layers.BatchNormalization()\n","            else:\n","                raise('Only \"bn\" (batchnorm) or None is allowed for normalization at this point')\n","        \n","        # Acitvation \n","        if self.act_fun:\n","            if self.act_fun == 'sign':\n","                self.act = SignActivation\n","            else:\n","                raise('Only \"sign\" (SignActivation) or None is allowed for activation at this point')\n","        \n","            \n","    def call(self, input): \n","        # TODO: unclear why in paper says no but here performs binarize\n","        # plus this is a tad hardcoded\n","        if input.shape[1] != 784 and self.bin_inp: \n","            input = Binarize(input)\n","            \n","        self.fc.kernel.assign(Binarize(self.fc.kernel.org))\n","        out = self.fc(input)\n","        \n","        if self.dropout_rate: \n","            out = self.dropout(out)\n","        \n","        if self.norm_type:\n","            out = self.norm(out)\n","        \n","        if self.act_fun:\n","            out = self.act(out)\n","        \n","        return out\n","\n","class BNN(Model):\n","    '''\n","    layers_dims:    [(input_height, input_width), hidden_1, hidden_2, ..., output]\n","    '''\n","    def __init__(self, layers_dims, **kwargs):\n","        super(BNN, self).__init__()\n","        self.layers_dims = layers_dims\n","        self.num_hidden = len(layers_dims) - 2\n","        \n","        self.hidden_args = dict(**kwargs)\n","\n","        self.output_args = dict(**kwargs)\n","        self.output_args['act_fun'] = None # no activation at output \n","        \n","        # define layers \n","        self.flatten = layers.Flatten(input_shape=layers_dims[0])\n","        self.bfcs = Sequential([\n","            BinarizeLinear(layers_dims[i], \n","                           **self.hidden_args, \n","                           name = 'bfc-%02d' %(i))\n","            for i in range(1, self.num_hidden+1)\n","        ])\n","        self.out = BinarizeLinear(layers_dims[-1], **self.output_args, name='output')\n","\n","    def call(self, x):\n","        x = self.flatten(x)\n","        x = self.bfcs(x)\n","        x = self.out(x)\n","        return x"],"execution_count":438,"outputs":[]},{"cell_type":"code","metadata":{"id":"2EbDK1xHziFS","executionInfo":{"status":"ok","timestamp":1635727183703,"user_tz":300,"elapsed":122,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["layer_dims = [(28,28), 512, 512, 10]\n","model = BNN(layer_dims)"],"execution_count":14,"outputs":[]},{"cell_type":"code","metadata":{"id":"cQMmVqCtBoTI","executionInfo":{"status":"ok","timestamp":1635728719722,"user_tz":300,"elapsed":1102,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["# ds = create_data_iter('MNIST', batch_size=batch_size, return_dict=True, return_iters=False)\n","Xs, Ys = next(iter(ds['train']))"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"id":"-BLMVEipzoVj","executionInfo":{"status":"ok","timestamp":1635728731423,"user_tz":300,"elapsed":140,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["Yhat = model(Xs)"],"execution_count":81,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LLarJ_19805D","executionInfo":{"status":"ok","timestamp":1635643518918,"user_tz":300,"elapsed":373,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"06786f0c-acd5-4726-a647-78a099724b34"},"source":["Yhat.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([100, 10])"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rz6Zx21jzpVK","executionInfo":{"status":"ok","timestamp":1635643984306,"user_tz":300,"elapsed":740,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"47e4b364-2ed2-4ad4-8fe5-5460044b2e74"},"source":["net.bfcs.weights[0].org"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(784, 512), dtype=float32, numpy=\n","array([[-0.00383681,  0.00398079, -0.00073914, ...,  0.01354782,\n","        -0.00127634, -0.00519177],\n","       [ 0.00605009, -0.0162162 , -0.0126883 , ..., -0.009854  ,\n","        -0.01828717, -0.00346346],\n","       [ 0.0032469 , -0.00669765, -0.00439042, ..., -0.00492112,\n","         0.0030536 ,  0.00801539],\n","       ...,\n","       [-0.01239286, -0.01238181, -0.00736965, ...,  0.0002927 ,\n","        -0.01229712, -0.01087759],\n","       [-0.00580652,  0.0207626 ,  0.00723688, ...,  0.00334233,\n","         0.0073972 , -0.02488009],\n","       [-0.03070979, -0.01668718, -0.0021343 , ...,  0.01404098,\n","        -0.01430478, -0.01959097]], dtype=float32)>"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","metadata":{"id":"JYDXXOSviTS7","executionInfo":{"status":"ok","timestamp":1635734801655,"user_tz":300,"elapsed":280,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.python.framework import ops\n","from tensorflow.python.ops import array_ops, control_flow_ops, math_ops, state_ops\n","from tensorflow.python.keras import backend_config\n","\n","import tensorflow_addons as tfa\n","from tensorflow_addons.optimizers import DecoupledWeightDecayExtension\n","\n","\n","class Adam_meta(keras.optimizers.Optimizer):\n","    '''\n","    Adam optimizer with `meta` parameter\n","\n","    PARAMETERS:\n","    - meta:   meta-plasticity parameter, for now only allows scalar values (in paper allows layer-wise)\n","\n","    NOTE:\n","        the rest parameters are similar to original Adam. But got rid of `decay`\n","\n","    TODO:\n","    - wrap around with [DecoupledWeightDecayExtension] -> Adam_meta_W\n","    - consider adding `f_meta` as an option\n","    - consider applying heterogeneity in `meta` like paper\n","\n","    SOURCE:\n","    - [Adam-keras](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/keras/optimizer_v2/adam.py)\n","    - [AdamW-keras](https://github.com/OverLordGoldDragon/keras-adamw/blob/master/keras_adamw/optimizers_v2.py)\n","    - [Adam_meta-Torch](https://github.com/Laborieux-Axel/SynapticMetaplasticityBNN/blob/master/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/models_utils.py)\n","    - [DecoupledWeightDecayExtension]: https://www.tensorflow.org/addons/api_docs/python/tfa/optimizers/DecoupledWeightDecayExtension\n","\n","    '''\n","\n","    def __init__(self,\n","                 meta=0,\n","                 learning_rate=0.001,\n","                 beta_1=0.9,\n","                 beta_2=0.999,\n","                 epsilon=1e-8,\n","                 amsgrad=False, \n","                 decay=0,\n","                 name=\"Adam-meta\",\n","                 **kwargs):\n","        # Check for conditions\n","        if min(meta, learning_rate, epsilon) < 0.0:\n","            raise ValueError('Invalid \"meta\" or \"learning_rate\" or \"epsilon\". Needs all to be non-negative')\n","        if min(beta_1, beta_2) < 0.0 or max(beta_1, beta_2) > 1.0:\n","            raise ValueError('Invalid \"beta_1\" or \"beta_2\". Needs both to be within [0,1]')\n","\n","        # Initialization and add hyperparameters\n","        super(Adam_meta, self).__init__(name, **kwargs)\n","\n","        self._set_hyper('learning_rate', kwargs.get('lr', learning_rate))\n","        self._set_hyper('meta', meta)\n","        self._set_hyper('beta_1', beta_1)\n","        self._set_hyper('beta_2', beta_2)\n","        self.decay = decay\n","        self.epsilon = epsilon or backend_config.epsilon()\n","        self.amsgrad = amsgrad\n","\n","    def _create_slots(self, var_list):\n","        '''Create slots for the first and second moments.\n","        Exactly similar to [AdamW-keras]\n","        '''\n","        for var in var_list:\n","            self.add_slot(var, 'm') # 1st moment\n","        for var in var_list:\n","            self.add_slot(var, 'v') # 2nd moment\n","        if self.amsgrad:\n","            for var in var_list:\n","                self.add_slot(var, 'vhat') # 2nd moment in case AMSGrad\n","        self._updates_per_iter = len(var_list)\n","\n","\n","    # @tf.function\n","    def _resource_apply_dense(self, grad, var):\n","        '''Update the slots and perform one optimization step for one model variable for metaplasticity\n","        This is mirroring [AdamW-keras] and [Adam_meta-Torch].\n","        '''\n","        var_device, var_dtype = var.device, var.dtype.base_dtype\n","\n","        # Get slots for 1st and 2nd moments\n","        m = self.get_slot(var, 'm')\n","        v = self.get_slot(var, 'v')\n","\n","        # Get hyperparameters\n","        meta_t = array_ops.identity(self._get_hyper('meta', var_dtype))\n","        lr_t = array_ops.identity(self._get_hyper('learning_rate', var_dtype))\n","        beta_1_t = array_ops.identity(self._get_hyper('beta_1', var_dtype))\n","        beta_2_t = array_ops.identity(self._get_hyper('beta_2', var_dtype))\n","        epsilon_t = ops.convert_to_tensor(self.epsilon, var_dtype)\n","        decay_t = ops.convert_to_tensor(self.decay, var_dtype)\n","\n","        # Compute parameters based on current local step\n","        local_step = math_ops.cast(self.iterations + 1, var_dtype)\n","        beta_1_power = math_ops.pow(beta_1_t, local_step) # B1^t\n","        beta_2_power = math_ops.pow(beta_2_t, local_step) # B2^t\n","\n","        # Learning rate bias correction\n","        # eta_t <- eta * sqrt(1-B2^t) / (1-B1^t)\n","        lr_t = lr_t * math_ops.sqrt(1 - beta_2_power) / (1 - beta_1_power)\n","\n","        # Essential ADAM equations\n","        # m: 1st moment\n","        # v: 2nd moment\n","        # g: grad\n","        # m <- B1 * m + (1 - B1) * g\n","        # v <- B2 * v + (1 - B2) * g^2\n","        if self.decay != 0:\n","            grad = math_ops.add(grad, math_ops.multiply(decay_t,var))\n","        m_t = state_ops.assign(m, beta_1_t * m + (1.0 - beta_1_t) * grad, use_locking=self._use_locking)\n","        v_t = state_ops.assign(v, beta_2_t * v + (1.0 - beta_2_t) * math_ops.square(grad), use_locking=self._use_locking)\n","\n","        # Apply AMSGrad if turned on\n","        # usually var_delta = dX <- m / (sqrt(v or v_hat) + eps)\n","        # var_delta_denom <- sqrt(v or v_hat) + eps\n","        # but metaplast will change a bit so only calc denom now\n","        if self.amsgrad: # v_hat <- max(v_hat, v_t)\n","            vhat = self.get_slot(var, 'vhat')\n","            vhat_t = state_ops.assign(vhat, math_ops.maximum(vhat, v_t), use_locking=self._use_locking)\n","            var_delta_denom = math_ops.sqrt(vhat_t) + epsilon_t\n","        else:\n","            var_delta_denom = math_ops.sqrt(v_t) + epsilon_t\n","\n","        # Metaplasticity\n","        if len(var.shape) == 1:  # True if bias or BN params, false if weight. TODO: Need to double check\n","            # X <- X - eta * sqrt(1-B2^t) / (1-B1^t) * m / (sqrt(v or v_hat) + eps)\n","            # X <- X - eta_t * dX\n","            # dX <- m / (var_delta_denom = sqrt(v or v_hat) + eps)\n","            var_t = math_ops.sub(var, lr_t * m_t / var_delta_denom)\n","        else:\n","            # the variables will be similar to [Adam_meta-Torch] code and try to mirror paper\n","            # binary_weight_before_update: Wb <- sign(Wh)\n","            # condition_consolidation: use_meta <- Uw * Wb > 0.0\n","            # Uw <- dX\n","            # Wh <- var\n","            Wb = math_ops.sign(var)\n","            use_meta = math_ops.multiply(Wb, m_t) > 0.0 # sign(m_t) = sign(dX)\n","\n","            # f_meta = 1 - tanh(m * Wh)^2\n","            f_meta = array_ops.ones_like(var) - math_ops.square(math_ops.tanh(meta_t * var))\n","\n","            # only use meta-applied m_t when use_meta = True\n","            # i.e. only use f_meta when Wb * m_t/denom > 0\n","            decayed_m_t = math_ops.multiply(f_meta, m_t)\n","            alt_m_t = array_ops.where(use_meta, decayed_m_t, m_t)\n","\n","            # X <- X - eta_t * dX\n","            # dX <- (f_meta(X=Wh) if Wb*Uw >0 else 1.0) * m / (var_delta_denom = sqrt(v or v_hat) + eps)\n","            var_t = math_ops.sub(var, lr_t * alt_m_t / var_delta_denom)\n","\n","        # Return updates\n","        var_update = state_ops.assign(var, var_t, use_locking=self._use_locking)\n","        updates = [var_update, m_t, v_t]\n","        if self.amsgrad:\n","            updates.append(vhat_t)\n","        return control_flow_ops.group(*updates)\n","\n","    def _resource_apply_sparse(self, grad, var):\n","        raise NotImplementedError\n","\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            'learning_rate': self._serialize_hyperparameter('learning_rate'),\n","            'meta': self._serialize_hyperparameter('meta'),\n","            'beta_1': self._serialize_hyperparameter('beta_1'),\n","            'beta_2': self._serialize_hyperparameter('beta_2'),\n","            'epsilon': self.epsilon,\n","            'amsgrad': self.amsgrad\n","        })\n","        return config\n","\n","class Adam_meta_W(DecoupledWeightDecayExtension, Adam_meta):\n","    '''\n","    NOTE: Untested\n","    '''\n","    def __init__(self,\n","                 weight_decay,\n","                 meta           = 0,\n","                 learning_rate  = 0.001,\n","                 beta_1         = 0.9,\n","                 beta_2         = 0.999,\n","                 epsilon        = 1e-8,\n","                 amsgrad        = False,\n","                 name           = \"Adam_meta_W\",\n","                 **kwargs):\n","        super().__init__(\n","            weight_decay,\n","            meta            = meta,\n","            learning_rate   = learning_rate,\n","            beta_1          = beta_1,\n","            beta_2          = beta_2,\n","            epsilon         = epsilon,\n","            amsgrad         = amsgrad,\n","            name            = name,\n","            **kwargs)"],"execution_count":430,"outputs":[]},{"cell_type":"code","metadata":{"id":"IqK7ptFG4u4S","executionInfo":{"status":"ok","timestamp":1635734880439,"user_tz":300,"elapsed":113,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["meta = 0.5\n","learning_rate = 0.005\n","weight_decay = 1e-7 \n","\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","\n","optimizer = Adam_meta(meta = meta, learning_rate = learning_rate, decay = weight_decay)\n","# optimizer = tfa.optimizers.extend_with_decoupled_weight_decay(Adam_meta)(weight_decay = weight_decay, meta = meta, learning_rate = learning_rate)\n","# optimizer = Adam_meta_W(weight_decay = weight_decay, meta = meta, learning_rate = learning_rate)\n","# optimizer = Adam_meta(meta = meta, learning_rate = learning_rate)\n","# optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n","# optimizerW = Adam_meta_W(weight_decay = weight_decay, meta = meta, learning_rate = learning_rate)\n"],"execution_count":439,"outputs":[]},{"cell_type":"code","metadata":{"id":"q9-5Dqx18Kxk","executionInfo":{"status":"ok","timestamp":1635735338038,"user_tz":300,"elapsed":180,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["layer_dims = [(28,28), 4096, 4096, 10]\n","model = BNN(layer_dims, init_type = 'uniform', init_width = 0.1, dropout_rate = None) # dropout_rate=None, norm_type=None)"],"execution_count":457,"outputs":[]},{"cell_type":"code","metadata":{"id":"gyW-0kDcBZjn","executionInfo":{"status":"ok","timestamp":1635734818211,"user_tz":300,"elapsed":1187,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["ds = create_data_iter('MNIST', batch_size=100, return_dict=True, return_iters=False)"],"execution_count":434,"outputs":[]},{"cell_type":"code","metadata":{"id":"0AdJZ9Le5Rp6","executionInfo":{"status":"ok","timestamp":1635734818212,"user_tz":300,"elapsed":4,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["train_loss = tf.keras.metrics.Mean(name='train_loss')\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n","\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","train_acc,test_acc = 0,0"],"execution_count":435,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ODFVWkTOHBV","executionInfo":{"status":"ok","timestamp":1635733043658,"user_tz":300,"elapsed":172,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["\n","for p in list(model.variables):\n","    if hasattr(p,'org'):\n","        break"],"execution_count":309,"outputs":[]},{"cell_type":"code","metadata":{"id":"KG6aJbj5PYOK"},"source":["for p in list(model.variables):\n","    if hasattr(p,'org'):\n","        p.assign(tf.identity(p.org))\n","        print(p)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qW-wTCbRQWAq"},"source":["for p in list(model.variables):  # updating the org attribute\n","    if hasattr(p,'org'):\n","        p.org = p\n","        print(p)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nqRRky-7OLJY"},"source":["p"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GoFlVFkZOL9J"},"source":["p.org"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iUH8ZOGn9w_i"},"source":["optimizer.get_config()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":164},"id":"Ygl_I9x4anyM","executionInfo":{"status":"error","timestamp":1635735212318,"user_tz":300,"elapsed":148,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"ae391130-9beb-4a21-df29-4064372c3032"},"source":["state_ops.assign()"],"execution_count":455,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-455-2a6626dd55c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'assign'"]}]},{"cell_type":"code","metadata":{"id":"3Z1IbtRH5UVN","executionInfo":{"status":"ok","timestamp":1635735339902,"user_tz":300,"elapsed":143,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["import copy \n","def calc_correct(predictions, labels):\n","    pred = tf.cast(tf.argmax(predictions), dtype='int64')\n","    labl = tf.cast(labels, dtype='int64')\n","    corr = tf.cast(pred == labl, dtype='float32')\n","    return tf.reduce_sum(corr)\n","\n","@tf.function\n","def train_step(images, labels):\n","    with tf.GradientTape() as tape:\n","        predictions = model(images, training=True)\n","        loss = loss_object(labels, predictions)\n","    gradients = tape.gradient(loss, model.trainable_variables)\n","\n","    for p in list(model.trainable_variables):\n","        if hasattr(p,'org'):\n","            p.assign(tf.identity(p.org))\n","\n","    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","    for p in list(model.trainable_variables):  # updating the org attribute\n","        if hasattr(p,'org'):\n","            p.org = state_ops.assign(p.org, p)\n","\n","    train_loss(loss)\n","    train_accuracy(labels, predictions)\n","    return calc_correct(labels, predictions)\n","\n","\n","@tf.function\n","def test_step(images, labels):\n","    # training=False is only needed if there are layers with different\n","    # behavior during training versus inference (e.g. Dropout).\n","    predictions = model(images, training=False)\n","    t_loss = loss_object(labels, predictions)\n","\n","    test_loss(t_loss)\n","    test_accuracy(labels, predictions)\n","    return calc_correct(labels, predictions)\n"],"execution_count":458,"outputs":[]},{"cell_type":"code","metadata":{"id":"0NgPUfRc8R-M","executionInfo":{"status":"ok","timestamp":1635731682390,"user_tz":300,"elapsed":144,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}}},"source":["from tqdm.notebook import tqdm"],"execution_count":195,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hzYVY7sKBIxJ","executionInfo":{"status":"ok","timestamp":1635732872085,"user_tz":300,"elapsed":139,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"b3c4dceb-6ada-4e37-f41b-c59f3e2187cb"},"source":["train_step(images, labels)"],"execution_count":289,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(), dtype=float32, numpy=16.0>"]},"metadata":{},"execution_count":289}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":611,"referenced_widgets":["01ea6cc3931c4c1c92053bf99df7d0ee","51cde6730e2f432c9b242c9230e7b524","fb750223edcc428d9d05f5eb59436e2e","526fcf9bdd044c87a2ac734a157f066d","5b0ac9a5304c4e41b5506510a726b402","ebaa479201214aea9bcab4737f23b29c","8ba6f263854d49d481f9271d1020d1df","c515bcded77347b995aa4b1cc35e0035","0a73ca26e2374ac6bfc3589eb83070ce","0379162367464b6b8605e6ed19264eeb","10dac26877d14bc1958bf28e85113a66"]},"id":"zT0eZaZz8NNp","executionInfo":{"status":"error","timestamp":1635735343040,"user_tz":300,"elapsed":1676,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"62e785a3-729a-413c-858b-fa7568c5ba5b"},"source":["%%time \n","num_epochs = 100\n","tf.executing_eagerly()\n","for epoch in tqdm(range(num_epochs)):\n","    # Reset the metrics at the start of the next epoch\n","    train_loss.reset_states()\n","    train_accuracy.reset_states()\n","    test_loss.reset_states()\n","    test_accuracy.reset_states()\n","    train_acc,test_acc = 0,0\n","\n","    for images, labels in iter(ds['train']):\n","        train_acc += train_step(images, labels)\n","\n","    for images, labels in iter(ds['test']):\n","        test_acc += test_step(images, labels)\n","\n","    print('\\t Epoch: %d | Loss: %.4f | Train Accuracy: %.2f | Test Acc: %.2f' \\\n","        %(epoch, train_loss.result(), train_accuracy.result() * 100, test_accuracy.result() * 100))\n","    print('%.2f, %.2f' %(train_acc, test_acc))"],"execution_count":459,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"01ea6cc3931c4c1c92053bf99df7d0ee","version_minor":0,"version_major":2},"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"]},"metadata":{}},{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-459-9462c34c4896>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"num_epochs = 100\\ntf.executing_eagerly()\\nfor epoch in tqdm(range(num_epochs)):\\n    # Reset the metrics at the start of the next epoch\\n    train_loss.reset_states()\\n    train_accuracy.reset_states()\\n    test_loss.reset_states()\\n    test_accuracy.reset_states()\\n    train_acc,test_acc = 0,0\\n\\n    for images, labels in iter(ds['train']):\\n        train_acc += train_step(images, labels)\\n\\n    for images, labels in iter(ds['test']):\\n        test_acc += test_step(images, labels)\\n\\n    print('\\\\t Epoch: %d | Loss: %.4f | Train Accuracy: %.2f | Test Acc: %.2f' \\\\\\n        %(epoch, train_loss.result(), train_accuracy.result() * 100, test_accuracy.result() * 100))\\n    print('%.2f, %.2f' %(train_acc, test_acc))\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    758\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    759\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 760\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3064\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3065\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3066\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3067\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3462\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3463\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3464\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3465\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3306\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3308\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3309\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3310\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1005\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1007\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 668\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    669\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    992\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    <ipython-input-458-297db4d83360>:23 train_step  *\n        p.org = state_ops.assign(p.org, p)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/state_ops.py:359 assign  **\n        return ref.assign(value, name=name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py:401 __getattr__\n        self.__getattribute__(name)\n\n    AttributeError: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'assign'\n"]}]},{"cell_type":"markdown","metadata":{"id":"fN8BSg_-FKlS"},"source":["# Testing OG torch version"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wAOvkA6bFM83","executionInfo":{"status":"ok","timestamp":1635735370713,"user_tz":300,"elapsed":130,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"fbd8632a-4f28-44a6-ef25-31d5433012b7"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","%cd \"/content/drive/MyDrive/Courses/Fall 2021/dlsys/bnn-cf-vs-robust/ext/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/\""],"execution_count":460,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/Courses/Fall 2021/dlsys/bnn-cf-vs-robust/ext/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmueunhrFlMI","executionInfo":{"status":"ok","timestamp":1635729699018,"user_tz":300,"elapsed":366,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"86582fe7-dbcc-4046-bcbb-090f7befe760"},"source":["!ls .."],"execution_count":137,"outputs":[{"output_type":"stream","name":"stdout","text":["CIFAR-features\t\t\t\t     README.md\n","Continual_Learning_Fig-2abcdefgh-3abcd-5cde  requirements.txt\n","LICENSE\t\t\t\t\t     Stream_Learning_CIFAR10_Fig-4b\n","MNIST-USPS\t\t\t\t     Stream_Learning_FMNIST_Fig-4a\n","Quadratic_Binary_Task_Fig-5ab\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i66YxSMyFHVE","executionInfo":{"status":"ok","timestamp":1635735581101,"user_tz":300,"elapsed":178533,"user":{"displayName":"Tuan Pham","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgG9io_G8UlUCnCJIPDToyzRUEWyAQYHjYGEIZsiA=s64","userId":"04312096117679155400"}},"outputId":"6015247f-66d5-4ab1-f701-f6754d870aec"},"source":["!python main.py --net 'bnn' --hidden-layers 512 512 --lr 0.005 --decay 1e-7 --meta 1.35 --epochs-per-task 10 --task-sequence 'MNIST' 'pMNIST' 'pMNIST' 'pMNIST'"],"execution_count":461,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:180.)\n","  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n","BNN(\n","  (layers): ModuleDict(\n","    (fc1): BinarizeLinear(in_features=784, out_features=512, bias=False)\n","    (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (fc2): BinarizeLinear(in_features=512, out_features=512, bias=False)\n","    (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","    (fc3): BinarizeLinear(in_features=512, out_features=10, bias=False)\n","    (bn3): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  )\n",")\n","/content/drive/My Drive/Courses/Fall 2021/dlsys/bnn-cf-vs-robust/ext/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/models_utils.py:369: UserWarning: This overload of add_ is deprecated:\n","\tadd_(Number alpha, Tensor other)\n","Consider using one of the following signatures instead:\n","\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1025.)\n","  grad.add_(group['weight_decay'], p.data)\n","Test accuracy: 57487/60000 (95.81%)\n","Test accuracy: 9518/10000 (95.18%)\n","Test accuracy: 58249/60000 (97.08%)\n","Test accuracy: 9591/10000 (95.91%)\n","Test accuracy: 58783/60000 (97.97%)\n","Test accuracy: 9705/10000 (97.05%)\n","Traceback (most recent call last):\n","  File \"main.py\", line 232, in <module>\n","    train_accuracy, train_loss = test(model, task, device, verbose=True)\n","  File \"/content/drive/My Drive/Courses/Fall 2021/dlsys/bnn-cf-vs-robust/ext/SynapticMetaplasticityBNN/Continual_Learning_Fig-2abcdefgh-3abcd-5cde/models_utils.py\", line 603, in test\n","    for data, target in test_loader:\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 521, in __next__\n","    data = self._next_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1186, in _next_data\n","    idx, data = self._get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1152, in _get_data\n","    success, data = self._try_get_data()\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 990, in _try_get_data\n","    data = self._data_queue.get(timeout=timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/queues.py\", line 104, in get\n","    if not self._poll(timeout):\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 257, in poll\n","    return self._poll(timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 414, in _poll\n","    r = wait([self], timeout)\n","  File \"/usr/lib/python3.7/multiprocessing/connection.py\", line 921, in wait\n","    ready = selector.select(timeout)\n","  File \"/usr/lib/python3.7/selectors.py\", line 415, in select\n","    fd_event_list = self._selector.poll(timeout)\n","KeyboardInterrupt\n"]}]}]}